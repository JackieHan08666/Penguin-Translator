# ğŸ§ Penguin-Translator: Transformer æ¶ˆèç ”ç©¶ä¸è‹±å¾·ç¿»è¯‘ç³»ç»Ÿ

[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-black?logo=github)](https://github.com/JackieHan08666/Penguin-Translator)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€æ¨¡å—åŒ–çš„ Transformer ç¥ç»æœºå™¨ç¿»è¯‘ï¼ˆNMTï¼‰å®éªŒå¹³å°ã€‚æˆ‘ä»¬ä¸ä»…å®ç°äº†æ ‡å‡†çš„ Transformer æ¶æ„ï¼Œè¿˜é’ˆå¯¹ Multi30k æ•°æ®é›†è®¾è®¡äº†ä¸€ç³»åˆ—æ¶ˆèå®éªŒï¼Œæ—¨åœ¨æ·±å…¥æ¢è®¨å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-head Attentionï¼‰ã€æ¨¡å‹æ·±åº¦åŠä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰å¯¹ç¿»è¯‘è´¨é‡çš„å½±å“ã€‚

---

## ğŸ— é¡¹ç›®æ¶æ„

```text
Penguin-Translator/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh              # ä¸€é”®å¼ç®¡ç†è„šæœ¬
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py            # æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ dataset.py          # æ•°æ®æµæ°´çº¿
â”‚   â”œâ”€â”€ train.py            # AMP è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ translate.py        # æ¨ç†å¼•æ“
â”‚   â””â”€â”€ plot_ablation.py    # ç»˜å›¾å·¥å…·
â”œâ”€â”€ results/                # æ—¥å¿—ä¸æƒé‡
â””â”€â”€ README.md
```

------

## âš¡ æ ¸å¿ƒä¼˜åŒ–æŠ€æœ¯

### 1. æ··åˆç²¾åº¦è®­ç»ƒ (Mixed-Precision)

åˆ©ç”¨ `torch.amp` è‡ªåŠ¨æ··åˆç²¾åº¦æŠ€æœ¯ï¼Œå°†è®¡ç®—å‹åŠ›å¤§çš„ç®—å­è½¬æ¢ä¸º **FP16**ã€‚

- **æ€§èƒ½æå‡**ï¼šåœ¨ RTX 3090 ä¸Šè®¡ç®—é€Ÿåº¦æå‡çº¦ **2.1x**ã€‚
- **æ˜¾å­˜å‹ç¼©**ï¼šå ç”¨é™ä½çº¦ **45%**ï¼Œæ”¯æŒå•å¡ 4 è¿›ç¨‹å¹¶è¡Œã€‚

### 2. å¢å¼ºå‹ Noam è°ƒåº¦ç­–ç•¥

é’ˆå¯¹å¤§ Batch Sizeï¼ˆ256ï¼‰ä¼˜åŒ–ï¼š

- **Warmup**ï¼šä¼˜åŒ–ä¸º 800 æ­¥ï¼Œç¡®ä¿åˆæœŸæ”¶æ•›ç¨³å®šã€‚
- **åŠ¨æ€ç¼©æ”¾**ï¼šéš $d_{model}$ è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ã€‚

### 3. é«˜æ€§èƒ½æ•°æ® I/O

- **å¤šçº¿ç¨‹åˆ†è¯**ï¼š`num_workers=4` æ¶ˆé™¤ CPU é˜»å¡ã€‚
- **é”é¡µå†…å­˜**ï¼š`pin_memory=True` å®ç°ç¡¬ä»¶çº§å¼‚æ­¥æ•°æ®æ‹·è´ã€‚

### 4. æ©ç æœºåˆ¶ä¸æº¢å‡ºé˜²æŠ¤

- **Safe-Masking**ï¼šé’ˆå¯¹ FP16 é‡æ–°è®¾è®¡å±è”½å€¼ï¼Œé˜²æ­¢æ•°å€¼æº¢å‡ºï¼ˆOverflowï¼‰ã€‚

### 5. Byte-Level BPE ä¼˜åŒ–

- **æ— æŸè¯è¡¨**ï¼šå¤„ç†ä»»æ„å¾·è¯­é•¿éš¾è¯ï¼Œå½»åº•è§£å†³ç©ºæ ¼ä¸¢å¤±é—®é¢˜ã€‚

------

## ğŸ“Š å®éªŒæ•°æ®ä¸åˆ†æ

| **å®éªŒç»„ (Experiment)** | **å‚æ•°é‡ (Params)** | **éªŒè¯é›†æœ€ä½ Loss** | **ç‰¹ç‚¹åˆ†æ**               |
| ----------------------- | ------------------- | ------------------- | -------------------------- |
| **Base (4H-2L)**        | **2,850,952**       | **2.8858**          | åŸºå‡†é…ç½®ï¼ŒæŒ‡æ ‡æœ€å‡è¡¡       |
| Ablation: 1-Head        | 2,850,952           | 2.9030              | å…³æ³¨ç‚¹å•ä¸€                 |
| Ablation: 1-Layer       | 2,388,104           | 2.9315              | æ·±åº¦å‡å°‘ï¼Œè¡¨ç°ç¨³å¥         |
| Ablation: No-PE         | 2,850,952           | 3.3195              | ä¸§å¤±è¯­åºæ„Ÿï¼Œè¯æ˜ PE å¿…è¦æ€§ |

### è®­ç»ƒæ›²çº¿å¯¹æ¯”

<p align="center">
  <img src="results/ablation_comparison.png" width="80%" title="Ablation Study Comparison">
  <br>
  <i>å›¾ 1: ä¸åŒ Transformer é…ç½®ä¸‹çš„éªŒè¯é›† Loss æ”¶æ•›æ›²çº¿å¯¹æ¯”</i>
</p>

------

## ğŸ’» ç¡¬ä»¶é…ç½®ä¸å»ºè®®

æœ¬é¡¹ç›®åœ¨ **NVIDIA GeForce RTX 3090 (24GB)** ä¸Šå®Œæˆã€‚

- **å•è¿›ç¨‹æ˜¾å­˜**: çº¦ 1.3 GB - 1.4 GB
- **æ€»æ˜¾å­˜å ç”¨**: çº¦ 5.7 GB / 24 GB
- **GPU è´Ÿè½½**: 100%

> **å»ºè®®**ï¼šè‹¥æ˜¾å­˜å……è¶³ï¼ˆ>=24GBï¼‰ï¼Œå¯å°è¯• Batch Size 512+ï¼›è‹¥æ˜¾å­˜è¾ƒå°ï¼ˆ8-12GBï¼‰ï¼Œå»ºè®®å•æ¬¡è¿è¡Œæˆ–å‡å°å¹¶è¡Œç»„æ•°ã€‚

------

## ğŸ§ äº¤äº’å¼ç¿»è¯‘æ¨¡å¼

1. è¿è¡Œ `./scripts/run.sh` é€‰æ‹© **3 (Translate)**ã€‚
2. **ç¥ç§˜å½©è›‹**ï¼šç›´æ¥æŒ‰ä¸‹ **[å›è½¦]** å°†è§¦å‘é¢„è®¾çš„ç¥ç§˜ä¾‹å¥ã€‚

------

## ğŸ›  å®‰è£…ä¸ä½¿ç”¨

Bash

```
# å…‹éš†ä»“åº“
git clone [https://github.com/JackieHan08666/Penguin-Translator.git](https://github.com/JackieHan08666/Penguin-Translator.git)
cd Penguin-Translator

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¯åŠ¨ç®¡ç†ä¸­å¿ƒ
chmod +x scripts/run.sh
./scripts/run.sh
```

